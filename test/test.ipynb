{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralNetwork.dense import Dense\n",
    "from NeuralNetwork.losses import mse,mse_derive,binary_crossentropy,binary_crossentropy_derive\n",
    "from NeuralNetwork.activations import Sigmoid,Softmax\n",
    "from NeuralNetwork.network import predict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "ALPHA = 0.1\n",
    "\n",
    "NN = [Dense(784,20),\n",
    "      Sigmoid(),\n",
    "      Dense(20,10),\n",
    "      Softmax()\n",
    "      ]\n",
    "\n",
    "\n",
    "def train(NN, loss, loss_derive, X, Y,x_test,y_test, epoch, alpha, verbose = True):\n",
    "    error_TS = []\n",
    "    acc_TS = []\n",
    "    val_error_TS = []\n",
    "    val_acc_TS = []\n",
    "    for e in range(epoch):\n",
    "        errors= 0\n",
    "        acc =0\n",
    "        val_error = 0\n",
    "        val_acc = 0\n",
    "        for x, y in zip(X, Y):\n",
    "            # forward\n",
    "            out = predict(NN, x)\n",
    "            if np.argmax(y)==np.argmax(out):\n",
    "                acc+=1\n",
    "            # error\n",
    "\n",
    "            errors+= loss(y, out)\n",
    "\n",
    "            # backward\n",
    "            gradient = loss_derive(y, out)\n",
    "            for layer in reversed(NN):\n",
    "                gradient = layer.backward(gradient, alpha)\n",
    "\n",
    "        for x, y in zip(x_test, y_test):\n",
    "            output = predict(NN, x)\n",
    "            if np.argmax(y)==np.argmax(output):\n",
    "                val_acc+=1\n",
    "            val_error += loss(y, output)\n",
    "        \n",
    "        errors/= len(X)\n",
    "        acc /=len(X)\n",
    "        val_error /= len(x_test)\n",
    "        val_acc /=len(x_test)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{e + 1}/{epoch}, error={round(errors,4)}, accuracy={round(acc,4)}, val_error={round(val_error,4)}, val_accuracy={round(val_acc,4)}\")\n",
    "        error_TS.append(errors)\n",
    "        acc_TS.append(acc)\n",
    "        val_error_TS.append(val_error)\n",
    "        val_acc_TS.append(val_acc)\n",
    "    return [error_TS,acc_TS,val_error_TS,val_acc_TS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_images_to_df(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _ = struct.unpack('>I', f.read(4))[0]\n",
    "        num_images = struct.unpack('>I', f.read(4))[0]\n",
    "        num_rows = struct.unpack('>I', f.read(4))[0]\n",
    "        num_cols = struct.unpack('>I', f.read(4))[0]\n",
    "        image_data = f.read(num_images * num_rows * num_cols)\n",
    "        images = np.frombuffer(image_data, dtype=np.uint8)\n",
    "        images = images.reshape(num_images, num_rows * num_cols)\n",
    "        df = pd.DataFrame(images)\n",
    "    return df\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic = struct.unpack('>I', f.read(4))[0]\n",
    "        num_labels = struct.unpack('>I', f.read(4))[0]\n",
    "        label_data = f.read(num_labels)\n",
    "        labels = np.frombuffer(label_data, dtype=np.uint8)        \n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_mnist_images_to_df('./dataset/train-images.idx3-ubyte')\n",
    "Y_train = load_mnist_labels('./dataset/train-labels.idx1-ubyte')\n",
    "X_test = load_mnist_images_to_df('./dataset/t10k-images.idx3-ubyte')\n",
    "Y_test = load_mnist_labels('./dataset/t10k-labels.idx1-ubyte')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./dataset/MNIST.csv\")\n",
    "\n",
    "Y_test,X_test =  df_train.iloc[:2000, :1], df_train.iloc[:2000, 1:]\n",
    "Y_train,X_train = df_train.iloc[2000:, :1], df_train.iloc[2000:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pca =PCA(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled,Y_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 236)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train =np.squeeze(np.eye(10)[Y_train])\n",
    "Y_test = np.squeeze(np.eye(10)[Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra\n",
    "X_in = np.reshape(X_train,X_train.shape +(1,))\n",
    "X_out = np.reshape(X_test,X_test.shape +(1,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_in = np.reshape(Y_train,Y_train.shape +(1,))\n",
    "Y_out = np.reshape(Y_test,Y_test.shape +(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_in \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mX_train_pca\u001b[49m,X_train_pca\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m      2\u001b[0m Y_in \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(Y_train,Y_train\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m      3\u001b[0m X_out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(X_test_pca,X_test_pca\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m1\u001b[39m,))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_pca' is not defined"
     ]
    }
   ],
   "source": [
    "X_in = np.reshape(X_train_pca,X_train_pca.shape +(1,))\n",
    "Y_in = np.reshape(Y_train,Y_train.shape +(1,))\n",
    "X_out = np.reshape(X_test_pca,X_test_pca.shape +(1,))\n",
    "Y_out = np.reshape(Y_test,Y_test.shape +(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/50, error=0.0817, accuracy=0.8535, val_error=0.0809, val_accuracy=0.8641\n",
      "2/50, error=0.0548, accuracy=0.9083, val_error=0.0662, val_accuracy=0.89\n",
      "3/50, error=0.0481, accuracy=0.9199, val_error=0.0488, val_accuracy=0.9215\n",
      "4/50, error=0.0448, accuracy=0.9266, val_error=0.0454, val_accuracy=0.9256\n",
      "5/50, error=0.0429, accuracy=0.9277, val_error=0.0441, val_accuracy=0.9304\n",
      "6/50, error=0.0406, accuracy=0.9325, val_error=0.0422, val_accuracy=0.9328\n",
      "7/50, error=0.04, accuracy=0.9333, val_error=0.0414, val_accuracy=0.9316\n",
      "8/50, error=0.0382, accuracy=0.9364, val_error=0.0559, val_accuracy=0.9163\n",
      "9/50, error=0.0371, accuracy=0.9391, val_error=0.0428, val_accuracy=0.9336\n",
      "10/50, error=0.0362, accuracy=0.9408, val_error=0.0456, val_accuracy=0.9279\n",
      "11/50, error=0.0347, accuracy=0.9424, val_error=0.0428, val_accuracy=0.9304\n",
      "12/50, error=0.0343, accuracy=0.9428, val_error=0.0411, val_accuracy=0.937\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_crossentropy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_crossentropy_derive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALPHA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m metrics_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(metrics_names)):\n",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(NN, loss, loss_derive, X, Y, x_test, y_test, epoch, alpha, verbose)\u001b[0m\n\u001b[1;32m     31\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m loss_derive(y, out)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(NN):\n\u001b[0;32m---> 33\u001b[0m         gradient \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x_test, y_test):\n\u001b[1;32m     36\u001b[0m     output \u001b[38;5;241m=\u001b[39m predict(NN, x)\n",
      "File \u001b[0;32m~/GITHUB/ELL784/test/NeuralNetwork/dense.py:13\u001b[0m, in \u001b[0;36mDense.backward\u001b[0;34m(self, output_gradient, learning_rate)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_gradient, learning_rate):\n\u001b[0;32m---> 13\u001b[0m     weights_gradient \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_gradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     input_gradient \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mT, output_gradient)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m weights_gradient\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = train(NN, binary_crossentropy, binary_crossentropy_derive, X=X_in,Y=Y_in,x_test=X_out,y_test=Y_out, epoch=EPOCHS, alpha=ALPHA)\n",
    "\n",
    "metrics_names = ['Training Loss','Training Accuracy','Test Loss','Test Accuracy']\n",
    "for i in range(len(metrics_names)):\n",
    "    plt.plot(metrics[i])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metrics_names[i])\n",
    "    plt.savefig(\"./graph/MNIST_{}.png\".format(metrics_names[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELL784-0C_wN4yj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
